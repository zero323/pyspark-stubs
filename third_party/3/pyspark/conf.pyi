# Stubs for pyspark.conf (Python 3.5)
#

from typing import overload
from typing import Any, List, Optional, Tuple

from py4j.java_gateway import JVMView, JavaObject  # type: ignore

class SparkConf:
    def __init__(
        self,
        loadDefaults: bool = ...,
        _jvm: Optional[JVMView] = ...,
        _jconf: Optional[JavaObject] = ...,
    ) -> None: ...
    def set(self, key: str, value: str) -> SparkConf: ...
    def setIfMissing(self, key: str, value: str) -> SparkConf: ...
    def setMaster(self, value: str) -> SparkConf: ...
    def setAppName(self, value: str) -> SparkConf: ...
    def setSparkHome(self, value: str) -> SparkConf: ...
    @overload
    def setExecutorEnv(self, key: str, value: str) -> SparkConf: ...
    @overload
    def setExecutorEnv(self, *, pairs: List[Tuple[str, str]]) -> SparkConf: ...
    def setAll(self, pairs: List[Tuple[str, str]]) -> SparkConf: ...
    def get(self, key: str, defaultValue: Optional[str] = ...) -> str: ...
    def getAll(self) -> List[Tuple[str, str]]: ...
    def contains(self, key: str) -> bool: ...
    def toDebugString(self) -> str: ...
