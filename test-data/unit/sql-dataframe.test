[case sampling]
from pyspark.sql import SparkSession

spark = SparkSession.builder.getOrCreate()
df = spark.range(1)
df.sample(1.0)
df.sample(0.5, 3)
df.sample(fraction=0.5, seed=3)
df.sample(withReplacement=True, fraction=0.5, seed=3)
df.sample(fraction=1.0)
df.sample(False, fraction=1.0)

# Will raise a runtime error, though not a typecheck error, as bool is
# duck-type compatible with float.
df.sample(True)

df.sample(withReplacement=False) # E: No overload variant of "sample" of "DataFrame" matches argument type "bool" \
                                 # N: Possible overload variants: \
                                 # N:     def sample(self, fraction: float, seed: Optional[int] = ...) -> DataFrame \
                                 # N:     def sample(self, withReplacement: Optional[bool], fraction: float, seed: Optional[int] = ...) -> DataFrame

[out]


[case dropColumns]
from pyspark.sql import SparkSession
from pyspark.sql.functions import lit, col
spark = SparkSession.builder.getOrCreate()
df = spark.range(1)
df.drop("id")
df.drop("id", "foo")
df.drop(df.id)

df.drop(col("id"), col("foo"))  # E: No overload variant of "drop" of "DataFrame" matches argument types "Column", "Column" \
                                # N: Possible overload variant:     \
                                # N:     def drop(self, *cols: str) -> DataFrame \
                                # N:     <1 more non-matching overload not shown>

[out]
